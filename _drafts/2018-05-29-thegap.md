---
layout: post
title: "The GAP"
date: 2017-07-25
---

This post is based on my experience working in RL for robotic control. 
It is about the "gap" I have perceived between the simulations and the real-world implementations of the RL controllers.

Moving from an RL based controller simulations to an actual implementation is not an obvious pathway for the following reasons:
<ol>
<li>To enable the controllability of a robot theoretically, we typically do a torque based control, i.e. we demand the desired torque at every instant. We take in joint angle input and joint velocity as feedback terms to proceed forward in time to complete the control loop. This is what all the simulations are based on.
</li>
<li>Torque control is simple in a simulation but would require advanced motor control strategies like FOC (Field Oriented Control) to achieve it in practice, which is limited to a very few research robots.
</li>
<li>Any typical robotic setting is capable of only position control or joint angle control and in some cases velocity control. But in our specific case since it is an industrial robot it works only on a set of defined waypoints which is not truly a position control.
</li>
<li>Typically such programming of such robots is done via waypoints, i.e. a set of way points are given as input and the planner plans a path along these points.</li>
<li>So we cannot deploy a custom controller to solve a task because of this manufacturer limitation!</li>
<li>Most of the current state of the art in RL is typically based on simulators with torque control (until recently atleast)</li>
<li>There are few ways to overcome this problem while implementation on the real robot like laying out a suitable  planner onto the existing controller to provide higher level control commands</li>
<li>
These differences in available sensorial data will affect the learning rate since richer the relevant observations the faster the robot “perceives” the situation and learns</li>
<ol>

