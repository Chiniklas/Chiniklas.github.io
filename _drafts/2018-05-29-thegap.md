---
layout: post
title: "The GAP"
date: 2017-07-25
---

This post is about my experience working in RL for robotic control. 
It is about the GAP I have perceived between the simulations and the real-world implementations of the RL controllers in reality.

Moving from an RL based controller simulations to an actual implementation is not an obvious pathway for the following reasons:
<ol>
<li>To enable the controllability of a robot theoretically, we typically do a torque based control, i.e. we demand the desired torque at every instant. We take in joint angle input and joint velocity as feedback terms to proceed forward in time to complete the control loop. This is what a simulations are based on.
</li>
<li>Torque control is simple in a simulation but would require advanced motor control strategies like FOC (Field Oriented Control) to achieve it in practice, which is limited to a very few research robots.
</li>
<li>Any typical robotic setting is capable of only position control or joint angle control and in some cases velocity control. But in our specific case since it is an industrial robot it works only on a set of defined waypoints which is not position control
</li>
<li>Programming such a robot is done with a task in mind and then move it based on the given waypoints</li>
<li>So we cannot deploy any typical controller to solve a task because of this manufacturer limitation!</li>
<li>Most of the current state of the art in RL is typically based on simulators with torque control until recently</li>
<li>There are few ways to overcome this problem to implement it on the real robot like laying out a suitable  planner onto the existing controller to provide higher level control commands</li>
<li>
These differences in available sensorial data will affect the learning rate since richer the relevant observations the faster the robot “perceives” the situation and learns</li>
<ol>

