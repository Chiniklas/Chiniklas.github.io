---
layout: default
title: "Reinforcement learning based control of an underactuated double pendulum system"
date: 2023-12-25
category: projects
image: /images/display_images/testbench_tmotor.jpg
authors: "<strong>Chi Zhang</strong>"
advisor: "Felix Wiebe, Akhil Sathuluri, Prof. Dr. Shivesh Kumar"
venue: "Master Thesis, Robotics Innovation Center, DFKI GmbH"
# preprint: /research/pdf/Extended_configuration_space_modelling__comparison_and_real_time_simulation_of_Lagrangian_dynamics_formulations_of_parallel_manipulators.pdf
code: https://github.com/Chiniklas/double_pendulum
---
In this project, control based on reinforcement learning (RL) was attempted on an underactuated double pendulum system. The tasks were the swinging up of the double pendulum and its stabilization around the highest point for an extended period of time. The inverted double pendulum system, by its nature, is chaotic, meaning that slight changes in its input can cause huge differences in its output. Due to the condition of underactuation, the control problem becomes very challenging to solve.<br><br>Two variations of underactuated control, namely acrobot and pendubot, are defined according to the joint that is to be controlled. A combined method of control is employed, consisting of a RL agent performing the swing-up and a Linear Quadratic Regulator (LQR) maintaining balance at the top. The RL agent is trained using a model-free RL algorithm called Soft Actor Critic (SAC). A three-stage reward function is defined to guide the agent into the region of attraction (RoA) of the LQR controller, where the controlled system becomes asymptotically stable towards the goal point.<br><br>In ideal environments, where real-world features like friction and signal delay are not included, successful validations are achieved in both acrobot and pendubot variations. For the transfer of the results to real-world hardware, several sim-to-real attempts are made in RL training, including domain randomization, noisy validation, and early termination. The results on real hardware are found to be successful only with the pendubot and not with the acrobot.<br><br>A leaderboard, consisting of performance metrics in simulation and the real world, as well as robustness metrics in simulation, is created to compare the results of RL-based control with conventional control methods like tvLQR, MPC, etc.<br><br>The results were presented at the IJCAI 2023 competition RealAIGym, and details are available in the pre-print paper.